<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>An Intro to Expectations via DiffEqUncertainty.jl · The SciML Tutorials</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://docs.sciml.ai/SciMLTutorialsOutput/stable/DiffEqUncertainty/01-expectation_introduction/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="The SciML Tutorials logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">The SciML Tutorials</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">SciMLTutorials.jl: Tutorials for Scientific Machine Learning (SciML) and Equation Solvers</a></li><li><span class="tocitem">Ordinary Differential Equation (ODE) Examples</span><ul><li><a class="tocitem" href="../../models/01-classical_physics/">Classical Physics Models</a></li><li><a class="tocitem" href="../../models/02-conditional_dosing/">Conditional Dosing Pharmacometric Example</a></li><li><a class="tocitem" href="../../models/03-kepler_problem/">Kepler Problem</a></li><li><a class="tocitem" href="../../models/04-spiking_neural_systems/">Spiking Neural Systems</a></li><li><a class="tocitem" href="../../models/05-outer_solar_system/">The Outer Solar System</a></li></ul></li><li><span class="tocitem">Special Analyses of ODEs</span><ul><li><a class="tocitem" href="../../odes/01-ode_minmax/">Finding Maxima and Minima of Ordinary Differential Equation Solutions</a></li></ul></li><li><span class="tocitem">Mixing Julia Types with Differential Equations</span><ul><li><a class="tocitem" href="../../type_handling/02-uncertainties/">Numbers with Uncertainties</a></li><li><a class="tocitem" href="../../type_handling/03-unitful/">Unit Checked Arithmetic via Unitful.jl</a></li></ul></li><li><span class="tocitem">Inference and Parameter Estimation on ODEs</span><ul><li><a class="tocitem" href="../../model_inference/01-pendulum_bayesian_inference/">Bayesian Inference on a Pendulum using DiffEqBayes.jl</a></li><li><a class="tocitem" href="../../model_inference/02-monte_carlo_parameter_estim/">Monte Carlo Parameter Estimation From Data</a></li></ul></li><li><span class="tocitem">Analyzing Jump Process Equations</span><ul><li><a class="tocitem" href="../../jumps/spatial/">Tutorial on using spatial SSAs in DiffEqJump</a></li></ul></li><li><span class="tocitem">Advanced ODE Examples</span><ul><li><a class="tocitem" href="../../advanced/01-beeler_reuter/">An Implicit/Explicit CUDA-Accelerated Solver for the 2D Beeler-Reuter Model</a></li><li><a class="tocitem" href="../../advanced/02-diffusion_implicit_heat_equation/">Solving the heat equation with diffusion-implicit time-stepping</a></li></ul></li><li><span class="tocitem">Uncertainty Quantification on ODEs</span><ul><li class="is-active"><a class="tocitem" href>An Intro to Expectations via DiffEqUncertainty.jl</a><ul class="internal"><li><a class="tocitem" href="#System-Model"><span>System Model</span></a></li><li><a class="tocitem" href="#Vector-Valued-Functions"><span>Vector-Valued Functions</span></a></li><li><a class="tocitem" href="#Higher-Order-Moments"><span>Higher-Order Moments</span></a></li><li><a class="tocitem" href="#Batch-Mode"><span>Batch-Mode</span></a></li><li><a class="tocitem" href="#Appendix"><span>Appendix</span></a></li></ul></li><li><a class="tocitem" href="../02-AD_and_optimization/">Optimization Under Uncertainty with DiffEqUncertainty.jl</a></li></ul></li><li><span class="tocitem">Symbolic-Numeric Approaches</span><ul><li><a class="tocitem" href="../../perturbation/01-perturbation_algebraic/">Mixed Symbolic/Numerical Methods for Perturbation Theory - Algebraic Equations</a></li><li><a class="tocitem" href="../../perturbation/02-perturbation_differential/">Mixed Symbolic/Numerical Methods for Perturbation Theory - Differential Equations</a></li></ul></li><li><span class="tocitem">Workshop Exercises</span><ul><li><a class="tocitem" href="../../exercises/01-workshop_exercises/">SciML Workshop Exercises</a></li><li><a class="tocitem" href="../../exercises/02-workshop_solutions/">SciML Workshop Exercise Solutions</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Uncertainty Quantification on ODEs</a></li><li class="is-active"><a href>An Intro to Expectations via DiffEqUncertainty.jl</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>An Intro to Expectations via DiffEqUncertainty.jl</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/SciMLTutorialsOutput/blob/main/docs/src/DiffEqUncertainty/01-expectation_introduction.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="An-Intro-to-Expectations-via-DiffEqUncertainty.jl"><a class="docs-heading-anchor" href="#An-Intro-to-Expectations-via-DiffEqUncertainty.jl">An Intro to Expectations via DiffEqUncertainty.jl</a><a id="An-Intro-to-Expectations-via-DiffEqUncertainty.jl-1"></a><a class="docs-heading-anchor-permalink" href="#An-Intro-to-Expectations-via-DiffEqUncertainty.jl" title="Permalink"></a></h1><h2 id="System-Model"><a class="docs-heading-anchor" href="#System-Model">System Model</a><a id="System-Model-1"></a><a class="docs-heading-anchor-permalink" href="#System-Model" title="Permalink"></a></h2><p>First, lets consider the following linear model.</p><p class="math-container">\[u&#39; = p u\]</p><pre><code class="language-julia hljs">
f(u,p,t) = p.*u</code></pre><pre><code class="nohighlight hljs">f (generic function with 1 method)</code></pre><p>We then wish to solve this model on the timespan <code>t=0.0</code> to <code>t=10.0</code>, with an intial condition <code>u0=10.0</code> and parameter <code>p=-0.3</code>. We can then setup the differential equations, solve, and plot as follows</p><pre><code class="language-julia hljs">
using DifferentialEquations, Plots
u0 = [10.0]
p = [-0.3]
tspan = (0.0,10.0)
prob = ODEProblem(f,u0,tspan,p)
sol = solve(prob)
plot(sol)
ylims!(0.0,10.0)</code></pre><p><img src="../figures/01-expectation_introduction_2_1.png" alt/></p><p>However, what if we wish to consider a random initial condition? Assume <code>u0</code> is distributed uniformly from <code>-10.0</code> to <code>10.0</code>, i.e.,</p><pre><code class="language-julia hljs">
using Distributions
u0_dist = [Uniform(-10.0,10.0)]</code></pre><pre><code class="nohighlight hljs">1-element Array{Distributions.Uniform{Float64},1}:
 Distributions.Uniform{Float64}(a=-10.0, b=10.0)</code></pre><p>We can then run a Monte Carlo simulation of 100,000 trajectories by solving an <code>EnsembleProblem</code>. </p><pre><code class="language-julia hljs">
prob_func(prob,i,repeat) = remake(prob, u0 = rand.(u0_dist))
ensemble_prob = EnsembleProblem(prob,prob_func=prob_func)

ensemblesol = solve(ensemble_prob,Tsit5(),EnsembleThreads(),trajectories=100000)</code></pre><pre><code class="nohighlight hljs">EnsembleSolution Solution of length 100000 with uType:
DiffEqBase.ODESolution{Float64,2,Array{Array{Float64,1},1},Nothing,Nothing,
Array{Float64,1},Array{Array{Array{Float64,1},1},1},DiffEqBase.ODEProblem{A
rray{Float64,1},Tuple{Float64,Float64},false,Array{Float64,1},DiffEqBase.OD
EFunction{false,typeof(Main.##WeaveSandBox#751.f),LinearAlgebra.UniformScal
ing{Bool},Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,N
othing,Nothing,Nothing,Nothing},Base.Iterators.Pairs{Union{},Union{},Tuple{
},NamedTuple{(),Tuple{}}},DiffEqBase.StandardODEProblem},OrdinaryDiffEq.Tsi
t5,OrdinaryDiffEq.InterpolationData{DiffEqBase.ODEFunction{false,typeof(Mai
n.##WeaveSandBox#751.f),LinearAlgebra.UniformScaling{Bool},Nothing,Nothing,
Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Nothing,Not
hing},Array{Array{Float64,1},1},Array{Float64,1},Array{Array{Array{Float64,
1},1},1},OrdinaryDiffEq.Tsit5ConstantCache{Float64,Float64}},DiffEqBase.DES
tats}</code></pre><p>Plotting the first 250 trajectories produces</p><pre><code class="language-julia hljs">
plot(ensemblesol, vars = (0,1), lw=1,alpha=0.1, label=nothing, idxs = 1:250)</code></pre><p><img src="../figures/01-expectation_introduction_5_1.png" alt/></p><p>Given the ensemble solution, we can then compute the expectation of a function <span>$g\left(\cdot\right)$</span> of the system state <code>u</code> at any time in the timespan, e.g. the state itself at <code>t=4.0</code> as</p><pre><code class="language-julia hljs">
g(sol) = sol(4.0)
mean([g(sol) for sol in ensemblesol])</code></pre><pre><code class="nohighlight hljs">1-element Array{Float64,1}:
 -0.007573120887912955</code></pre><p>Alternatively, DiffEqUncertainty.jl offers a convenient interface for this type of calculation, <code>expectation()</code>.</p><pre><code class="language-julia hljs">
using DiffEqUncertainty
expectation(g, prob, u0_dist, p, MonteCarlo(), Tsit5(); trajectories=100000)</code></pre><pre><code class="nohighlight hljs">1-element Array{Float64,1}:
 -0.0037433989352062547</code></pre><p><code>expectation()</code> takes the function of interest <span>$g$</span>, an <code>ODEProblem</code>, the initial conditions and parameters, and an <code>AbstractExpectationAlgorithm</code>. Here we use <code>MonteCarlo()</code> to use the Monte Carlo algorithm. Note that the initial conditions and parameters can be arrays that freely mix numeric and continuous distribution types from Distributions.jl. Recall, that <code>u0_dist = [Uniform(-10.0,10.0)]</code>, while <code>p = [-0.3]</code>. From this specification, the expectation is solved as</p><p class="math-container">\[\mathbb{E}\left[g\left(X\right)\vert X\sim Pf\right]\]</p><p>where <span>$Pf$</span> is the &quot;push-forward&quot; density of the initial joint pdf <span>$f$</span> on initial conditions and parameters. </p><p>Alternatively, we could solve the same problem using the <code>Koopman()</code> algorithm. </p><pre><code class="language-julia hljs">
expectation(g, prob, u0_dist, p, Koopman(), Tsit5())</code></pre><pre><code class="nohighlight hljs">u: 1-element Array{Float64,1}:
 0.0</code></pre><p>Being that this system is linear, we can analytically compute the solution as a deterministic ODE with its initial condition set to the expectation of the initial condition, i.e.,</p><p class="math-container">\[e^{pt}\mathbb{E}\left[u_0\right]\]</p><pre><code class="language-julia hljs">
exp(p[1]*4.0)*mean(u0_dist[1])</code></pre><pre><code class="nohighlight hljs">0.0</code></pre><p>We see that for this case the <code>Koopman()</code> algorithm produces a more accurate solution than <code>MonteCarlo()</code>. Not only is it more accurate, it is also much faster</p><pre><code class="language-julia hljs">
@time expectation(g, prob, u0_dist, p, MonteCarlo(), Tsit5(); trajectories=100000)</code></pre><pre><code class="nohighlight hljs">2.280767 seconds (79.32 M allocations: 7.160 GiB, 71.23% gc time)
1-element Array{Float64,1}:
 -0.0050382269528445305</code></pre><pre><code class="language-julia hljs">
@time expectation(g, prob, u0_dist, p, Koopman(), Tsit5())</code></pre><pre><code class="nohighlight hljs">0.000798 seconds (12.26 k allocations: 1.111 MiB)
u: 1-element Array{Float64,1}:
 0.0</code></pre><p>Changing the distribution, we arrive at</p><pre><code class="language-julia hljs">
u0_dist = [Uniform(0.0,10.0)]
@time expectation(g, prob, u0_dist, p, MonteCarlo(), Tsit5(); trajectories=100_000)</code></pre><pre><code class="nohighlight hljs">1.027060 seconds (79.30 M allocations: 7.160 GiB, 44.15% gc time)
1-element Array{Float64,1}:
 1.5059653813564504</code></pre><p>and</p><pre><code class="language-julia hljs">
@time expectation(g, prob, u0_dist, p, Koopman(), Tsit5())[1]</code></pre><pre><code class="nohighlight hljs">0.004259 seconds (14.02 k allocations: 1.221 MiB)
1.5059722133001539</code></pre><p>where the analytical solution is </p><pre><code class="language-julia hljs">
exp(p[1]*4.0)*mean(u0_dist[1])</code></pre><pre><code class="nohighlight hljs">1.5059710595610105</code></pre><p>Note that the <code>Koopman()</code> algorithm doesn&#39;t currently support infinite or semi-infinite integration domains, where the integration domain is determined by the extrema of the given distributions. So, trying to using a <code>Normal</code> distribution will produce <code>NaN</code></p><pre><code class="language-julia hljs">
u0_dist = [Normal(3.0,2.0)]
expectation(g, prob, u0_dist, p, Koopman(), Tsit5())</code></pre><pre><code class="nohighlight hljs">u: 1-element Array{Float64,1}:
 NaN</code></pre><p>Here, the analytical solution is </p><pre><code class="language-julia hljs">
exp(p[1]*4.0)*mean(u0_dist[1])</code></pre><pre><code class="nohighlight hljs">0.9035826357366062</code></pre><p>Using a truncated distribution will alleviate this problem. However, there is another gotcha. If a large majority of the probability mass of the distribution exists in a small region in the support, then the adaptive methods used to solve the expectation can &quot;miss&quot; the non-zero portions of the distribution and errantly return 0.0.</p><pre><code class="language-julia hljs">
u0_dist = [truncated(Normal(3.0,2.0),-1000,1000)]
expectation(g, prob, u0_dist, p, Koopman(), Tsit5())</code></pre><pre><code class="nohighlight hljs">u: 1-element Array{Float64,1}:
 0.0</code></pre><p>whereas truncating at <span>$\pm 4\sigma$</span> produces the correct result</p><pre><code class="language-julia hljs">
u0_dist = [truncated(Normal(3.0,2.0),-5,11)]
expectation(g, prob, u0_dist, p, Koopman(), Tsit5())</code></pre><pre><code class="nohighlight hljs">u: 1-element Array{Float64,1}:
 0.9035833577709517</code></pre><p>If a large truncation is required, it is best practice to center the distribution on the truncated interval. This is because many of the underlying quadrature algorithms use the center of the interval as an evaluation point.</p><pre><code class="language-julia hljs">
u0_dist = [truncated(Normal(3.0,2.0),3-1000,3+1000)]
expectation(g, prob, u0_dist, p, Koopman(), Tsit5())</code></pre><pre><code class="nohighlight hljs">u: 1-element Array{Float64,1}:
 0.903584360812248</code></pre><h2 id="Vector-Valued-Functions"><a class="docs-heading-anchor" href="#Vector-Valued-Functions">Vector-Valued Functions</a><a id="Vector-Valued-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-Valued-Functions" title="Permalink"></a></h2><p><code>expectation()</code> can also handle vector-valued functions. Simply pass the vector-valued function and set the <code>nout</code> kwarg to the length of the vector the function returns.</p><p>Here, we demonstrate this by computing the expectation of <code>u</code> at <code>t=4.0s</code> and <code>t=6.0s</code></p><pre><code class="language-julia hljs">
g(sol) = [sol(4.0)[1], sol(6.0)[1]]
expectation(g, prob, u0_dist, p, Koopman(), Tsit5(); nout = 2)</code></pre><pre><code class="nohighlight hljs">u: 2-element Array{Float64,1}:
 0.903584360812248
 0.49589556820916314</code></pre><p>with analytical solution</p><pre><code class="language-julia hljs">
exp.(p.*[4.0,6.0])*mean(u0_dist[1])</code></pre><pre><code class="nohighlight hljs">2-element Array{Float64,1}:
 0.9035826357366062
 0.4958966646647597</code></pre><p>this can be used to compute the expectation at a range of times simultaneously</p><pre><code class="language-julia hljs">
saveat = tspan[1]:.5:tspan[2]
g(sol) = Matrix(sol)
mean_koop = expectation(g, prob, u0_dist, p, Koopman(), Tsit5(); nout = length(saveat), saveat=saveat)</code></pre><pre><code class="nohighlight hljs">u: 1×21 Array{Float64,2}:
 3.0  2.58213  2.22246  1.91289  1.64644  …  0.201619  0.173536  0.149364</code></pre><p>We can then plot these values along with the analytical solution</p><pre><code class="language-julia hljs">
plot(t-&gt;exp(p[1]*t)*mean(u0_dist[1]),tspan..., xlabel=&quot;t&quot;, label=&quot;analytical&quot;)
scatter!(collect(saveat),mean_koop.u[:],marker=:o, label=nothing)</code></pre><p><img src="../figures/01-expectation_introduction_23_1.png" alt/></p><h3 id="Benefits-of-Using-Vector-Valued-Functions"><a class="docs-heading-anchor" href="#Benefits-of-Using-Vector-Valued-Functions">Benefits of Using Vector-Valued Functions</a><a id="Benefits-of-Using-Vector-Valued-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Benefits-of-Using-Vector-Valued-Functions" title="Permalink"></a></h3><p>In the above examples we used vector-valued expectation calculations to compute the various expectations required. Alternatively, one could simply compute multiple scalar-valued expectations. However, in most cases it is more efficient to use the vector-valued form. This is especially true when the ODE to be solved is computationally expensive.</p><p>To demonstrate this, lets compute the expectation of <span>$x$</span>, <span>$x^2$</span>, and <span>$x^3$</span> using both approaches while counting the number of times <code>g()</code> is evaluated. This is the same as the number of simulation runs required to arrive at the solution. First, consider the scalar-valued approach. Here, we follow the same method as before, but we add a counter to our function evaluation that stores the number of function calls for each expectation calculation to an array.</p><pre><code class="language-julia hljs">
function g(sol, power, counter)
    counter[power] = counter[power] + 1
    sol(4.0)[1]^power
end

counters = [0,0,0]
x_koop = expectation(s-&gt;g(s,1,counters), prob, u0_dist, p, Koopman(), Tsit5())
x2_koop = expectation(s-&gt;g(s,2,counters), prob, u0_dist, p, Koopman(), Tsit5())
x3_koop = expectation(s-&gt;g(s,3,counters), prob, u0_dist, p, Koopman(), Tsit5())
counters</code></pre><pre><code class="nohighlight hljs">3-element Array{Int64,1}:
 375
 405
 375</code></pre><p>Leading to a total of 1155 function evaluations.</p><p>Now, lets compare this to the vector-valued approach</p><pre><code class="language-julia hljs">
function g(sol, counter) 
    counter[1] = counter[1] + 1
    v = sol(4.0)[1]
    [v, v^2, v^3]
end

counter = [0]
expectation(s-&gt;g(s,counter), prob, u0_dist, p, Koopman(), Tsit5(); nout = 3)
counter</code></pre><pre><code class="nohighlight hljs">1-element Array{Int64,1}:
 405</code></pre><p>This is 35.06% the number of simulations required when using scalar-valued expectations. Note how the number of evaluations used in the vector-valued form is equivelent to the maximum number of evaluations for the 3 scalar-valued expectation calls.</p><h2 id="Higher-Order-Moments"><a class="docs-heading-anchor" href="#Higher-Order-Moments">Higher-Order Moments</a><a id="Higher-Order-Moments-1"></a><a class="docs-heading-anchor-permalink" href="#Higher-Order-Moments" title="Permalink"></a></h2><p>Leveraging this vector-valued capability, we can also efficiently compute higher-order central moments.</p><h3 id="Variance"><a class="docs-heading-anchor" href="#Variance">Variance</a><a id="Variance-1"></a><a class="docs-heading-anchor-permalink" href="#Variance" title="Permalink"></a></h3><p>The variance, or 2nd central moment, of a random variable <span>$X$</span> is defined as</p><p class="math-container">\[\mathrm{Var}\left(X\right)=\mathbb{E}\left[\left(X-\mu\right)^2\right]\]</p><p>where</p><p class="math-container">\[\mu = \mathbb{E}\left[X\right]\]</p><p>The expression for the variance can be expanded to</p><p class="math-container">\[\mathrm{Var}\left(X\right)=\mathbb{E}\left[X^2\right]-\mathbb{E}\left[X\right]^2\]</p><p>Using this, we define a function that returns the expectations of <span>$X$</span> and <span>$X^2$</span> as a vector-valued function and then compute the variance from these</p><pre><code class="language-julia hljs">
function g(sol) 
    x = sol(4.0)[1]
    [x, x^2]
end

koop = expectation(g, prob, u0_dist, p, Koopman(), Tsit5(); nout = 2)
mean_koop = koop[1]
var_koop = koop[2] - mean_koop^2</code></pre><pre><code class="nohighlight hljs">0.36287237175498144</code></pre><p>For a linear system, we can propagate the variance analytically as</p><p class="math-container">\[e^{2pt}\mathrm{Var}\left(u_0\right)\]</p><pre><code class="language-julia hljs">
exp(2*p[1]*4.0)*var(u0_dist[1])</code></pre><pre><code class="nohighlight hljs">0.36287181315765005</code></pre><p>This can be computed at multiple time instances as well</p><pre><code class="language-julia hljs">
saveat = tspan[1]:.5:tspan[2]
g(sol) = [Matrix(sol)&#39;; (Matrix(sol).^2)&#39;]

koop = expectation(g, prob, u0_dist, p, Koopman(), Tsit5(); nout = length(saveat)*2, saveat=saveat)
μ = koop.u[1:length(saveat)]
σ = sqrt.(koop.u[length(saveat)+1:end] - μ.^2)

plot(t-&gt;exp(p[1]*t)*mean(u0_dist[1]),tspan..., ribbon = t-&gt;-sqrt(exp(2*p[1]*t)*var(u0_dist[1])), label=&quot;Analytical Mean, 1 std bounds&quot;)
scatter!(collect(saveat),μ,marker=:x, yerror = σ, c=:black, label = &quot;Koopman Mean, 1 std bounds&quot;)</code></pre><p><img src="../figures/01-expectation_introduction_28_1.png" alt/></p><h3 id="Skewness"><a class="docs-heading-anchor" href="#Skewness">Skewness</a><a id="Skewness-1"></a><a class="docs-heading-anchor-permalink" href="#Skewness" title="Permalink"></a></h3><p>A similar approach can be used to compute skewness</p><pre><code class="language-julia hljs">
function g(sol) 
    v = sol(4.0)[1]
    [v, v^2, v^3]
end

koop = expectation(g, prob, u0_dist, p, Koopman(), Tsit5(); nout = 3)
mean_koop = koop[1]
var_koop = koop[2] - mean_koop^2
(koop[3] - 3.0*mean_koop*var_koop - mean_koop^3) / var_koop^(3/2)</code></pre><pre><code class="nohighlight hljs">3.7952822389774445e-9</code></pre><p>As the system is linear, we expect the skewness to be unchanged from the inital distribution. Becasue the distribution is a truncated Normal distribution centered on the mean, the true skewness is <code>0.0</code>.</p><h3 id="nth-Central-Moment"><a class="docs-heading-anchor" href="#nth-Central-Moment">nth Central Moment</a><a id="nth-Central-Moment-1"></a><a class="docs-heading-anchor-permalink" href="#nth-Central-Moment" title="Permalink"></a></h3><p>DiffEqUncertainty provides a convenience function <code>centralmoment</code> around this approach for higher-order central moments. It takes an integer for the number of central moments you wish to compute. While the rest of the arguments are the same as for  <code>expectation()</code>. The following will return central moments 1-5.</p><pre><code class="language-julia hljs">
g(sol) = sol(4.0)[1]
centralmoment(5, g, prob, u0_dist, p, Koopman(), Tsit5(),
                ireltol = 1e-9, iabstol = 1e-9)</code></pre><pre><code class="nohighlight hljs">5-element Array{Float64,1}:
 0.0
 0.3628723692985327
 4.026725619610261e-10
 0.39502906894683987
 1.2523240222606091e-9</code></pre><h2 id="Batch-Mode"><a class="docs-heading-anchor" href="#Batch-Mode">Batch-Mode</a><a id="Batch-Mode-1"></a><a class="docs-heading-anchor-permalink" href="#Batch-Mode" title="Permalink"></a></h2><p>It is also possible to solve the various simulations in parallel by using the <code>batch</code> kwarg and a batch-mode supported quadrature algorithm via the <code>quadalg</code> kwarg. To view the list of batch compatible quadrature algorithms, refer to <a href="https://github.com/SciML/Quadrature.jl">Quadrature.jl</a>. Note: Batch-mode operation is built on top of DifferentialEquation.jl&#39;s <code>EnsembleProblem</code>. See the <a href="https://diffeq.sciml.ai/stable/features/ensemble/">EnsembleProblem documentation</a> for additional options.</p><p>The default quadtrature algorithm used by <code>expectation()</code> does not support batch-mode evaluation. So, we first load dependencies for additional quadrature algorithms</p><pre><code class="language-julia hljs">using Quadrature, Cuba</code></pre><p>We then solve our expectation as before using a <code>batch=10</code> multi-thread parallelization via <code>EnsembleThreads()</code> of Cuba&#39;s SUAVE algorithm. However, in this case we introduce additional uncertainty in the model parameter.</p><pre><code class="language-julia hljs">
u0_dist = [truncated(Normal(3.0,2.0),-5,11)]
p_dist = [truncated(Normal(-.7, .1), -1,0)]

g(sol) = sol(6.0)[1]

expectation(g, prob, u0_dist, p_dist, Koopman(), Tsit5(), EnsembleThreads(); 
                quadalg = CubaSUAVE(), batch=10)[1]</code></pre><pre><code class="nohighlight hljs">0.05397860786456136</code></pre><p>Now, lets compare the performance of the batch and non-batch modes</p><pre><code class="language-julia hljs">
using BenchmarkTools

@btime expectation(g, prob, u0_dist, p_dist, Koopman(), Tsit5(); 
                quadalg = CubaSUAVE())[1]</code></pre><pre><code class="nohighlight hljs">44.556 ms (1006187 allocations: 91.55 MiB)
0.05397860786456136</code></pre><pre><code class="language-julia hljs">
@btime expectation(g, prob, u0_dist, p_dist, Koopman(), Tsit5(), EnsembleThreads(); 
                quadalg = CubaSUAVE(), batch=10)[1]</code></pre><pre><code class="nohighlight hljs">21.936 ms (1019426 allocations: 93.00 MiB)
0.05397860786456136</code></pre><p>It is also possible to parallelize across the GPU. However, one must be careful of the limitations of ensemble solutions with the GPU. Please refer to <a href="https://github.com/SciML/DiffEqGPU.jl">DiffEqGPU.jl</a> for details.</p><p>Here we load <code>DiffEqGPU</code> and modify our problem to use Float32 and to put the ODE in the required GPU form</p><pre><code class="language-julia hljs">
using DiffEqGPU

function f(du, u,p,t) 
    @inbounds begin
        du[1] = p[1]*u[1];
    end
    nothing
end

u0 = Float32[10.0]
p = Float32[-0.3]
tspan = (0.0f0,10.0f0)
prob = ODEProblem(f,u0,tspan,p)

g(sol) = sol(6.0)[1]

u0_dist = [truncated(Normal(3.0f0,2.0f0),-5f0,11f0)]
p_dist = [truncated(Normal(-.7f0, .1f0), -1f0,0f0)]

@btime expectation(g, prob, u0_dist, p_dist, Koopman(), Tsit5(), EnsembleGPUArray(); 
                   quadalg = CubaSUAVE(), batch=1000)[1]</code></pre><pre><code class="nohighlight hljs">6.861 ms (76204 allocations: 3.71 MiB)
0.056093966910433016</code></pre><p>The performance gains realized by leveraging batch GPU processing is problem dependent. In this case, the number of batch evaluations required to overcome the overhead of using the GPU exceeds the number of simulations required to converge to the quadrature solution.</p><h2 id="Appendix"><a class="docs-heading-anchor" href="#Appendix">Appendix</a><a id="Appendix-1"></a><a class="docs-heading-anchor-permalink" href="#Appendix" title="Permalink"></a></h2><p>This tutorial is part of the SciMLTutorials.jl repository, found at: <a href="https://github.com/SciML/SciMLTutorials.jl">https://github.com/SciML/SciMLTutorials.jl</a>.  For more information on doing scientific machine learning (SciML) with open source software, check out <a href="https://sciml.ai/">https://sciml.ai/</a>.</p><p>To locally run this tutorial, do the following commands:</p><pre><code class="nohighlight hljs">using SciMLTutorials
SciMLTutorials.weave_file(&quot;DiffEqUncertainty&quot;,&quot;01-expectation_introduction.jmd&quot;)</code></pre><p>Computer Information:</p><pre><code class="nohighlight hljs">Julia Version 1.4.2
Commit 44fa15b150* (2020-05-23 18:35 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Core(TM) i7-9700K CPU @ 3.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_LOAD_PATH = /builds/JuliaGPU/DiffEqTutorials.jl:
  JULIA_DEPOT_PATH = /builds/JuliaGPU/DiffEqTutorials.jl/.julia
  JULIA_CUDA_MEMORY_LIMIT = 2147483648
  JULIA_NUM_THREADS = 8
</code></pre><p>Package Information:</p><pre><code class="nohighlight hljs">Status `/builds/JuliaGPU/DiffEqTutorials.jl/tutorials/DiffEqUncertainty/Project.toml`
[6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf] BenchmarkTools 0.5.0
[8a292aeb-7a57-582c-b821-06e4c11590b1] Cuba 2.1.0
[071ae1c0-96b5-11e9-1965-c90190d839ea] DiffEqGPU 1.6.0
[41bf760c-e81c-5289-8e54-58b1f1f8abe2] DiffEqSensitivity 6.31.1
[ef61062a-5684-51dc-bb67-a0fcdec5c97d] DiffEqUncertainty 1.5.0
[0c46a032-eb83-5123-abaf-570d42b7fbaa] DifferentialEquations 6.15.0
[31c24e10-a181-5473-b8eb-7969acd0382f] Distributions 0.23.8
[f6369f11-7733-5829-9624-2563aa707210] ForwardDiff 0.10.12
[76087f3c-5699-56af-9a33-bf431cd00edd] NLopt 0.6.0
[1dea7af3-3e70-54e6-95c3-0bf5283fa5ed] OrdinaryDiffEq 5.42.3
[91a5bcdd-55d7-5caf-9e0b-520d859cae80] Plots 1.6.0
[67601950-bd08-11e9-3c89-fd23fb4432d2] Quadrature 1.3.0</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../advanced/02-diffusion_implicit_heat_equation/">« Solving the heat equation with diffusion-implicit time-stepping</a><a class="docs-footer-nextpage" href="../02-AD_and_optimization/">Optimization Under Uncertainty with DiffEqUncertainty.jl »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Saturday 26 November 2022 00:41">Saturday 26 November 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
